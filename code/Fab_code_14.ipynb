{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import fftpack\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = os.getcwd() + '\\\\data\\\\'\n",
    "extension = 'csv'\n",
    "\n",
    "os.chdir(path)\n",
    "titles = glob.glob('*.{}'.format(extension))\n",
    "print(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datasets = []\n",
    "for d in titles:\n",
    "    data = pd.read_csv(path + d)\n",
    "    if len(data.columns) == 1:\n",
    "        data = pd.read_csv(path + d, sep=\";\")\n",
    "    data['action'] = data['Stimulus'].apply(lambda x: x.replace(' ', '.').split('.')[0])\n",
    "    datasets.append(data[data.columns[1:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = datasets[1]\n",
    "print(list(data.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sb.set_context(\"paper\")\n",
    "for c in data.columns[1:-1]:\n",
    "    plt.figure()\n",
    "    sb.violinplot(data[c], data.action)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curve similarity by eye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_confidence(data):\n",
    "    avg = np.mean(data, axis = 0)\n",
    "    sd = np.std(data, axis = 0)\n",
    "    \n",
    "    plt.plot(avg)\n",
    "    plt.fill_between(list(range(len(avg))), avg - sd, avg + sd, alpha=.3, facecolor='red')\n",
    "\n",
    "    \n",
    "def pre_analysis(data, action, repetitions, wave, stimulus_len = None):\n",
    "    dt = data[data.action == action].copy()\n",
    "    dt = dt[wave]\n",
    "    \n",
    "    if stimulus_len is None:\n",
    "        stimulus_len = int(dt.shape[0] / repetitions)\n",
    "        \n",
    "    datamatrix = np.zeros([repetitions, stimulus_len])\n",
    "    for i in range(repetitions):\n",
    "        datamatrix[i, :] = dt[i*stimulus_len:(i+1)*stimulus_len]\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.title(action)\n",
    "    plot_confidence(datamatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "wave = \"AF3\"\n",
    "for action in set(data.action.values):\n",
    "    pre_analysis(data, action, 30, wave)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Signal Subsetting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Split the signals into small subsets with an overlap\n",
    "def subset_data(data, ss_dim = None, ss_num = 10, overlap = .5, cut_smaller = True):\n",
    "    if overlap > 1: # in case the value passed is a percentage\n",
    "        overlap = float(overlap)/100\n",
    "        \n",
    "    if ss_dim is None: # either choose the dimension of the subsets or the number\n",
    "        ss_dim = int(len(data)/(ss_num*overlap)) # by default it will divide the signal in 10 subsets\n",
    "    \n",
    "    subsets = []\n",
    "    i = len(data) - 1\n",
    "    while i >= 0:\n",
    "        j = max(i - ss_dim, 0)\n",
    "        subsets.append(data[j:i])\n",
    "        i -= int(ss_dim * (1 - overlap))\n",
    "    \n",
    "    while cut_smaller and len(subsets[-1]) < ss_dim :\n",
    "        subsets = subsets[:-1]\n",
    "        \n",
    "    return np.array(subsets)\n",
    "\n",
    "def prepare_data(dataframe, ss_dim = 20, ss_num = 168, overlap = .5):\n",
    "    dataset = {}\n",
    "    for action in set(dataframe.action.values):\n",
    "        a = []\n",
    "        data = dataframe[dataframe.action == action].copy()\n",
    "        for c in data.columns[1:-1]:\n",
    "            a.append(np.array(subset_data(np.array(data[c]), ss_dim, ss_num, overlap, cut_smaller = True)))\n",
    "        dataset[action] = [np.asmatrix(d).flatten() for d in np.transpose(np.array(a), [1, 2, 0])] # if you want a list of matrixes\n",
    "        #dataset[action] = np.transpose(np.array(a), [1, 2, 0]) # if you want a tensor\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = prepare_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(dataset[\"run\"]), dataset['run'][0].shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn.cluster as csr\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_pivot_table(Y, actions):\n",
    "    pivot_table = np.zeros([len(actions), clust_num])\n",
    "    for i, action in enumerate(actions):\n",
    "        for cluster in range(clust_num):\n",
    "            pivot_table[i, cluster] = len( Y[(Y.action == action) & (Y.cluster == cluster)] )\n",
    "    return pivot_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.zeros([0, 280])\n",
    "labels = []\n",
    "for t in dataset.keys():\n",
    "    x = np.squeeze(dataset[t], axis = 1)\n",
    "    labels += [t for i in range(int(x.shape[0]))]\n",
    "    X = np.concatenate((X, x))\n",
    "X = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clust_num = 7\n",
    "ac = csr.AgglomerativeClustering(n_clusters = clust_num, compute_full_tree=True)\n",
    "ac.fit(X)\n",
    "clust_labels = ac.labels_\n",
    "\n",
    "Y=pd.DataFrame(data = {'action': labels, 'cluster': clust_labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "actions = list(set(data.action.values))\n",
    "pivot_table = make_pivot_table(Y, actions)\n",
    "print(actions)\n",
    "print(pivot_table)\n",
    "print(sp.stats.chisquare(pivot_table, axis=0)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Bruteforce parameter optimizer\n",
    "dimensions = [10, 15, 20, 30, 50]\n",
    "cluster_number = [4, 5, 6, 7, 8]\n",
    "\n",
    "combination = []\n",
    "for dim in dimensions:\n",
    "    dataset = prepare_data(data, ss_dim = dim)\n",
    "\n",
    "    X = np.zeros([0, 14*dim])\n",
    "    labels = []\n",
    "    for t in dataset.keys():\n",
    "        x = np.squeeze(dataset[t], axis = 1)\n",
    "        labels += [t for i in range(int(x.shape[0]))]\n",
    "        X = np.concatenate((X, x))\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    for clust_num in cluster_number:\n",
    "        ac = csr.AgglomerativeClustering(n_clusters = clust_num)\n",
    "        ac.fit(X)\n",
    "        clust_labels = ac.labels_\n",
    "        Y = pd.DataFrame(data = {'action': labels, 'cluster': clust_labels})\n",
    "        actions = list(set(Y.action.values))\n",
    "        pivot_table = make_pivot_table(Y, actions)\n",
    "        p_values = sp.stats.chisquare(pivot_table, axis=0)[1]\n",
    "        combination.append([dim, clust_num, pivot_table, p_values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print actions\n",
    "for combo in combination:\n",
    "    for c in combo:\n",
    "        print(c)\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fourier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt = data[\"AF3\"]\n",
    "dt = dt[data.Stimulus == \"jump.png\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "FFT = abs(sp.fft(dt))\n",
    "freqs = sp.fftpack.fftfreq(dt.size, 0.01)\n",
    "plt.plot(freqs,20*sp.log10(FFT),'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

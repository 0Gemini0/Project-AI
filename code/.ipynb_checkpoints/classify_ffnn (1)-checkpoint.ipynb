{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import fftpack\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import glob\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = os.getcwd() + '\\\\data\\\\'\n",
    "print(os.getcwd())\n",
    "extension = 'csv'\n",
    "\n",
    "os.chdir(path)\n",
    "titles = glob.glob('*.{}'.format(extension))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datasets = []\n",
    "    \n",
    "for d in titles:\n",
    "    data = pd.read_csv(path + d)\n",
    "    if len(data.columns) == 1:\n",
    "        data = pd.read_csv(path + d, sep=\";\")\n",
    "    data['action'] = data['Stimulus'].apply(lambda x: x.replace(' ', '.').split('.')[0])\n",
    "    datasets.append(data[data.columns[1:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(datasets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_action(stimulus):\n",
    "    action_nr = stimulus.split('.')[0]\n",
    "    splitted = action_nr.split('-')\n",
    "    action = splitted[0]\n",
    "    if len(splitted) == 1:\n",
    "        nr = '0'\n",
    "    else:\n",
    "        nr = splitted[1]\n",
    "    return action.strip(), nr.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "actions = {}\n",
    "\n",
    "data = datasets[0]\n",
    "data = data[data.columns[1:]]\n",
    "\n",
    "data = data['action']\n",
    "i = 0\n",
    "\n",
    "for d in data:\n",
    "    action,number = extract_action(d)\n",
    "\n",
    "    if not action in list(actions.keys()):\n",
    "        actions[action] = i\n",
    "        i += 1\n",
    "        print('added', action)\n",
    "        \n",
    "action_length = len(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Xs = []\n",
    "# X = None\n",
    "# Ys = None\n",
    "# lowest = float('inf')\n",
    "\n",
    "# for i in range(len(datasets)):\n",
    "#     data = datasets[i]\n",
    "#     rows = data.iterrows() \n",
    "#     j = 0\n",
    "#     previous_action = None\n",
    "#     previous_number = None\n",
    "#     for i in range(data.shape[0]):\n",
    "#         row = next(rows)[1]\n",
    "#         x = np.array(row[2:])\n",
    "#         action,number = extract_action(row[1])\n",
    "#         y = actions[action]\n",
    "\n",
    "#         if previous_action == None:\n",
    "#             previous_action = action\n",
    "\n",
    "#         if previous_number == None:\n",
    "#             previous_number = number\n",
    "\n",
    "\n",
    "#         if not action == previous_action or not number == previous_number:\n",
    "\n",
    "#             if len(X) < lowest:\n",
    "#                 lowest = len(X)\n",
    "\n",
    "#             X = None\n",
    "\n",
    "#         if X == None:\n",
    "#             X = x\n",
    "#         else:\n",
    "#             X = np.append(X,x) \n",
    "\n",
    "#         previous_action = action\n",
    "#         previous_number = number\n",
    "\n",
    "# print('Shortest signal length is:', lowest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Xs = None\n",
    "# X = None\n",
    "# Ys = None\n",
    "\n",
    "# for i in range(len(datasets)):\n",
    "#     data = datasets[i]\n",
    "#     rows = data.iterrows() \n",
    "#     j = 0\n",
    "#     previous_action = None\n",
    "#     previous_number = None\n",
    "#     for i in range(data.shape[0]):\n",
    "#         row = next(rows)[1]\n",
    "#         x = np.array(row[2:])\n",
    "#         action,number = extract_action(row[1])\n",
    "#         y = actions[action]\n",
    "\n",
    "#         if previous_action == None:\n",
    "#             previous_action = action\n",
    "\n",
    "#         if previous_number == None:\n",
    "#             previous_number = number\n",
    "\n",
    "\n",
    "#         if not action == previous_action or not number == previous_number:\n",
    "\n",
    "#             X = X[:lowest]\n",
    "\n",
    "#             if Xs == None:\n",
    "#                 Xs = X\n",
    "#             else:\n",
    "#                 Xs = np.vstack((Xs,X))\n",
    "\n",
    "#             if Ys == None:\n",
    "#                 Ys = np.array(y)\n",
    "#             else:\n",
    "#                 Ys = np.append(Ys,y)\n",
    "\n",
    "#             X = None\n",
    "\n",
    "#         if X == None:\n",
    "#             X = x\n",
    "#         else:\n",
    "#             X = np.append(X,x) \n",
    "\n",
    "#         previous_action = action\n",
    "#         previous_number = number\n",
    "    \n",
    "    \n",
    "# #     cutoff start\n",
    "# #     if not previous_action == None and not strcmp(action,previous_action):\n",
    "# #         if j > 40:\n",
    "# #             while j < 70:\n",
    "# #                 x = np.zeros()\n",
    "# #                 X.append(x)\n",
    "# #             Xs.append(X)\n",
    "# #             Ys.append(y)\n",
    "# #             X = None\n",
    "# #             previous_action = None\n",
    "# #         continue\n",
    "            \n",
    "\n",
    "# #     index = actions[action]\n",
    "# #     y[index] = 1\n",
    "    \n",
    "# #     if X == None:\n",
    "# #         X = x\n",
    "# #     else:\n",
    "# #         X.append(x)\n",
    "    \n",
    "# #     previous_action = action\n",
    "    \n",
    "# #     if j == 70:\n",
    "# #         j = 0\n",
    "# #         Xs.append(X)\n",
    "# #         Ys.append(y)\n",
    "# #         previous_action = None\n",
    "# #         X = None\n",
    "        \n",
    "# # if j > 40:\n",
    "# #     while j < 70:\n",
    "# #         x = np.zeros()\n",
    "# #         X.append(x)\n",
    "# #     Xs.append(X)\n",
    "# #     Ys.append(y)\n",
    "    \n",
    "# print(Xs.shape)\n",
    "# print(Ys.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Split the signals into small subsets with an overlap\n",
    "def subset_data(data, ss_dim = None, ss_num = 10, overlap = .5, cut_smaller = True):\n",
    "    if overlap > 1: # in case the value passed is a percentage\n",
    "        overlap = float(overlap)/100\n",
    "        \n",
    "    if ss_dim is None: # either choose the dimension of the subsets or the number\n",
    "        ss_dim = int(len(data)/(ss_num*overlap)) # by default it will divide the signal in 10 subsets\n",
    "    \n",
    "    subsets = []\n",
    "    i = len(data) - 1\n",
    "    while i >= 0:\n",
    "        j = max(i - ss_dim, 0)\n",
    "        subsets.append(data[j:i])\n",
    "        i -= int(ss_dim * (1 - overlap))\n",
    "    \n",
    "    while cut_smaller and len(subsets[-1]) < ss_dim :\n",
    "        subsets = subsets[:-1]\n",
    "        \n",
    "    return np.array(subsets)\n",
    "\n",
    "def prepare_data(dataframe, ss_dim = 20, ss_num = 168, overlap = .5):\n",
    "    dataset = {}\n",
    "    for action in set(dataframe.action.values):\n",
    "        a = []\n",
    "        data = dataframe[dataframe.action == action].copy()\n",
    "        for c in data.columns[1:-1]:\n",
    "            a.append(np.array(subset_data(np.array(data[c]), ss_dim, ss_num, overlap, cut_smaller = True)))\n",
    "        dataset[action] = [np.asmatrix(d).flatten() for d in np.transpose(np.array(a), [1, 2, 0])] # if you want a list of matrixes\n",
    "        #dataset[action] = np.transpose(np.array(a), [1, 2, 0]) # if you want a tensor\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for data in datasets:\n",
    "    dataset = prepare_data(data, ss_dim = 1, overlap = 0)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = None\n",
    "Y = None\n",
    "\n",
    "for t in dataset.keys():\n",
    "    \n",
    "    x = np.squeeze(dataset[t], axis = 1)\n",
    "    \n",
    "    if X is None:\n",
    "        X = x   \n",
    "    else:\n",
    "        X = np.concatenate( (X, x))\n",
    "        \n",
    "        \n",
    "    y = np.array([actions[t]])\n",
    "    y = np.tile(y,len(x))\n",
    "    \n",
    "    if Y is None:\n",
    "        Y = y\n",
    "    else:\n",
    "        Y = np.concatenate((Y,y))\n",
    "\n",
    "X = StandardScaler().fit_transform(X)\n",
    "print(len(X))\n",
    "print(len(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from random import shuffle\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=42)\n",
    "\n",
    "cutoff = round(len(X) * 0.)  #80-20 division\n",
    "Z = list(zip(X,Y))\n",
    "shuffle(Z)\n",
    "\n",
    "X,Y = zip(*Z)\n",
    "print(Y)\n",
    "\n",
    "\n",
    "X_train = X[0:cutoff]\n",
    "y_train = Y[:cutoff]\n",
    "X_test = X[cutoff: -1]\n",
    "y_test = Y[cutoff: -1]\n",
    "\n",
    "\n",
    "inp = X_train\n",
    "out = y_train\n",
    "\n",
    "#print(out)\n",
    "\n",
    "def classify_net(inp, out):\n",
    "    clf = MLPClassifier(solver=\"lbfgs\", alpha=1e-4,hidden_layer_sizes=(100),random_state=1, max_iter=2000)\n",
    "    print(clf.fit(inp, out))\n",
    "    #print(clf.predict(inp))\n",
    "    print(clf.score(X_test,y_test))\n",
    "    \n",
    "def classify_knn(inp, out, n):\n",
    "    clf = KNeighborsClassifier(n_neighbors=n, weights='distance')\n",
    "    print(clf.fit(inp, out))\n",
    "    #print(clf.predict(inp))\n",
    "    print(clf.score(X_test,y_test))\n",
    "    \n",
    "    \n",
    "classify_net(inp,out)\n",
    "for i in range(1,10):\n",
    "    print(i)\n",
    "    classify_knn(inp,out,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import fftpack\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BCI Anonymous Jun 09 12h55.raw.csv', 'BCI subj03 Jun 09 12h47.raw.csv', 'BCI subj04 Jun 09 16h01.raw.csv']\n"
     ]
    }
   ],
   "source": [
    "path = os.getcwd() + '\\\\data\\\\'\n",
    "extension = 'csv'\n",
    "\n",
    "os.chdir(path)\n",
    "titles = glob.glob('*.{}'.format(extension))\n",
    "print(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datasets = []\n",
    "for d in titles:\n",
    "    data = pd.read_csv(path + d)\n",
    "    if len(data.columns) == 1:\n",
    "        data = pd.read_csv(path + d, sep=\";\")\n",
    "    data['action'] = data['Stimulus'].apply(lambda x: x.replace(' ', '.').split('.')[0])\n",
    "    datasets.append(data[data.columns[1:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Stimulus', 'AF3', 'F7', 'F3', 'FC5', 'T7', 'P7', 'O1', 'O2', 'P8', 'T8', 'FC6', 'F4', 'F8', 'AF4', 'action']\n"
     ]
    }
   ],
   "source": [
    "data = datasets[0]\n",
    "print(list(data.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sb.set_context(\"paper\")\n",
    "for c in data.columns[1:-1]:\n",
    "    plt.figure()\n",
    "    sb.violinplot(data[c], data.action)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curve similarity by eye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_confidence(data):\n",
    "    avg = np.mean(data, axis = 0)\n",
    "    sd = np.std(data, axis = 0)\n",
    "    \n",
    "    plt.plot(avg)\n",
    "    plt.fill_between(list(range(len(avg))), avg - sd, avg + sd, alpha=.3, facecolor='red')\n",
    "\n",
    "    \n",
    "def pre_analysis(data, action, repetitions, wave, stimulus_len = None):\n",
    "    dt = data[data.action == action].copy()\n",
    "    dt = dt[wave]\n",
    "    \n",
    "    if stimulus_len is None:\n",
    "        stimulus_len = int(dt.shape[0] / repetitions)\n",
    "        \n",
    "    datamatrix = np.zeros([repetitions, stimulus_len])\n",
    "    for i in range(repetitions):\n",
    "        datamatrix[i, :] = dt[i*stimulus_len:(i+1)*stimulus_len]\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.title(action)\n",
    "    plot_confidence(datamatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "wave = \"AF3\"\n",
    "for action in set(data.action.values):\n",
    "    pre_analysis(data, action, 10, wave)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Signal Subsetting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Split the signals into small subsets with an overlap\n",
    "def subset_data(data, ss_dim = None, ss_num = 10, overlap = .5, cut_smaller = True):\n",
    "    if overlap > 1: # in case the value passed is a percentage\n",
    "        overlap = float(overlap)/100\n",
    "        \n",
    "    if ss_dim is None: # either choose the dimension of the subsets or the number\n",
    "        ss_dim = int(len(data)/(ss_num*overlap)) # by default it will divide the signal in 10 subsets\n",
    "    \n",
    "    subsets = []\n",
    "    i = len(data) - 1\n",
    "    while i >= 0:\n",
    "        j = max(i - ss_dim, 0)\n",
    "        subsets.append(data[j:i])\n",
    "        i -= int(ss_dim * (1 - overlap))\n",
    "    \n",
    "    while cut_smaller and len(subsets[-1]) < ss_dim :\n",
    "        subsets = subsets[:-1]\n",
    "        \n",
    "    return np.array(subsets)\n",
    "\n",
    "def prepare_data(dataframe, ss_dim = 20, ss_num = 168, overlap = .5):\n",
    "    dataset = {}\n",
    "    for action in set(dataframe.action.values):\n",
    "        a = []\n",
    "        data = dataframe[dataframe.action == action].copy()\n",
    "        for c in data.columns[1:-1]:\n",
    "            a.append(np.array(subset_data(np.array(data[c]), ss_dim, ss_num, overlap, cut_smaller = True)))\n",
    "        #dataset[action] = [np.asmatrix(d) for d in np.transpose(np.array(a), [1, 2, 0])] # if you want a list of matrixes\n",
    "        dataset[action] = np.transpose(np.array(a), [1, 2, 0]) # if you want a tensor\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = prepare_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(283L, 20L, 14L)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"run\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fourier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt = data[\"AF3\"]\n",
    "dt = dt[data.Stimulus == \"jump.png\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "FFT = abs(sp.fft(dt))\n",
    "freqs = sp.fftpack.fftfreq(dt.size, 0.01)\n",
    "plt.plot(freqs,20*sp.log10(FFT),'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
